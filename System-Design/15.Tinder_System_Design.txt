ğŸ“Œ Tinder System Design

ğŸ¯ Picking Features
â¤ In interviews, don't rush into tech choices (e.g., services, DBs); step back and think logically about what features your users need first.

â¤ Prefer the front-to-back approach:
Start with user features â†’ break into services â†’ define data requirements per service. This keeps the system flexible and practical.

â¤ Core Features Chosen for Tinder:
1. Storing profiles (with images (5 atmost)).
2. Recommending matches (suggesting people to swipe).
3. Noting matches (track mutual swipes).
4. Direct messaging (chat after match).

ğŸ–¼ï¸ Storing Images
â¤ Every user can have up to 5 images, which adds significant storage overhead.
â¤ Debate: File system vs Blob (Binary Large Object) in a database.

ğŸ“ File vs Blob Storage Analysis
â¤ Mutability:
Images are rarely updated; better to treat them as immutable and replace instead of update.
So, mutability support from DBs is unnecessary.

â¤ Transaction Guarantees:
Not needed for images; atomic writes not essential here.

â¤ Indexing:
DB indexes help with structured data, not with image content (binary). Hence, irrelevant for images.
 
â¤ Access Control:
Both DB and file systems offer control. Setting up secure file systems is as viable as databases.

â¤ Why Prefer File Systems?
1. Cheaper than database blob storage.
2. Faster for large object reads/writes.
3. Built-in support for CDNs (Content Delivery Networks) for fast image delivery.
4. Avoids accidental large reads like SELECT * (no risk of pulling full image blobs unintentionally).

ğŸ—ƒï¸ Storage Design for Images
â¤ Use distributed file system for storing actual images.
â¤ Use database to store metadata:
Fields: image_id, profile_id, image_url.
â¤ This model supports scalable image serving, file referencing, and future enhancements (e.g., ML processing).

ğŸ“² System Design: User Interaction with Profile Service
â¤ The user interacts with the system through the mobile client, which sends a request to register with the profile service using details like username and password.

â¤ Although actual production systems involve more security (e.g., email verification, 2FA), for simplicity, this flow assumes that the profile service also handles email verifications.

â¤ After registration, the user typically updates their profile (name, description, and photos), which raises the authentication questionâ€”how do we verify the request is from the legitimate user?

ğŸ” Authentication Flow and Its Optimization
â¤ Initially, authentication could be managed inside the profile service using username and password or token-based authentication.

â¤ Token authentication is preferred in interviews; however, if every service has to do this repeatedly, it results in duplicate auth logic across services.

â¤ To resolve this, introduce a Gateway Service:
1. All client requests go through this gateway.
2. The gateway validates the token by checking with the profile service.
3. If valid, the request is routed to the correct internal service; otherwise, it fails early.
4. This decouples authentication responsibility from each microservice and standardizes security.

ğŸ§© Separation of Image Service
â¤ The user might update their name or description frequently, but images are heavier and used differently, e.g., by ML systems or other features that require only images.

â¤ Therefore, itâ€™s logical to separate image storage from the profile service into an Image Service:
1. Stores actual image files in a distributed file system.
2. Maintains a database with mappings:
    1.1 profile_id, image_id, and the URL pointing to the image file.

â¤ This decoupling improves scalability, maintainability, and allows different teams or services to interact with images independently.

ğŸ’¬ Direct Messaging (Chat)
â¤ In Tinder, once two users match, they need to exchange messages. The client (user) initiates a request to send a message to another matched user's ID via the Gateway (e.g., message to userID 1 from userID 2).

â¤ Traditional protocols like HTTP follow a client-server model where the client always initiates communication. This model is inefficient for chat, as it would require the client to poll the server repeatedly (e.g., every 5 seconds) asking if there are new messages, which leads to performance issues.

â¤ To enable real-time, two-way communication, a peer-to-peer (P2P) protocol is preferred, where both parties are treated equally. This allows servers to push messages to clients.

ğŸ”— Protocol Choice: XMPP vs HTTP
â¤ XMPP (Extensible Messaging and Presence Protocol) is a peer-to-peer communication protocol suited for chat apps, allowing servers to push messages directly to clients without polling.

â¤ In contrast, HTTP is a request-response protocol and isn't ideal for chat unless workarounds like long polling or HTTP/2 streams are used.

â¤ So in a system design interview, itâ€™s good to mention both:
1. HTTP (for traditional client-server).
2. XMPP or WebSockets (for persistent, bi-directional chat connections).

ğŸ§µ WebSocket / TCP for Persistent Connections
â¤ The client and server maintain a WebSocket connection, which is a lightweight, persistent connection over TCP.

â¤ Alternatively, you could mention TCP directly, saying, "I'll write my own protocol over TCP," which shows protocol-level understanding.

â¤ These open connections allow the server to push chat messages instantly as they arrive, improving latency and user experience.

ğŸ“¡ Session Management Service
â¤ While the Gateway Service handles routing, it should not be responsible for managing user-to-connection mappings. This leads to coupling and code duplication.

â¤ Instead, introduce a dedicated Session Management Service, which maintains a mapping of:
user_id â†’ connection_id

â¤ This allows the system to identify which socket or connection the target user is currently using and then route messages accordingly.

â¤ The Session Service supports real-time messaging by telling the system where a user is connected, enabling push-based delivery of messages.

ğŸ’˜ Matching Algorithm (Noting Matches)
â¤ Although storing match history on the client seems feasible, itâ€™s riskyâ€”server should remain the source of truth to avoid data loss (e.g., app uninstall).

â¤ Introduce a Matcher Service: Maintains a table of user_id â†’ matched_user_id to track bidirectional matches (e.g., if A matches with B, then B matches with A is also stored). Indexes are applied to both user IDs.

â¤ Before sending a direct message, the system checks with the Matcher Service to validate the match, then forwards it to the Session Service, which determines the active connection for the matched user. This ensures only matched users can chat with each other.

ğŸ¯ Recommendation Engine
â¤ The biggest challenge is finding nearby users while also applying filters like gender and age. While filtering by gender/age is index-friendly, location is tricky due to its complexity.

â¤ Many assume multiple indexes solve the problem, but a relational DB table can only efficiently use one index per query. This limits performance for combined filters.

ğŸ”„ Solving Multi-Index Problem: Cassandra or Sharding
â¤ Option 1: Use NoSQL like Cassandra/DynamoDB
These distributed DBs replicate data and let you create query-specific tables, making multi-parameter filtering efficient.

â¤ Option 2: Sharding (Horizontal Partitioning)
1. Data is partitioned based on some field (e.g., user name Aâ€“J in node 1, Kâ€“P in node 2). This is called horizontal sharding.
2. Enables locating the correct DB node quickly based on data range.

ğŸ›¡ï¸ Sharding + Fault Tolerance
â¤ To prevent single points of failure in sharding:
1. Use master-slave architecture within each shard.
2. If the master node fails, the slave takes over, maintaining availability.

â¤ Be ready to justify sharding over distributed DBs (like Cassandra) during interviews. Cassandra offers many features out-of-the-box, while sharding is more complex to maintain.

ğŸ“ Sharding by Location for Recommendations
â¤ Partition users based on location chunks (e.g., lat/lon grids), and then within each chunk:
1. Use indexes to filter by age.
2. Then apply a final gender filter manually.

â¤ This process ensures scalable and fast user recommendations based on geo and profile criteria.

ğŸ§  Recommendation Service
â¤ Stores or fetches relevant user IDs based on location (can reuse profile service data or keep its own).

â¤ Location updates are periodic (e.g., every 1â€“3 hours) from the client to reduce overhead and enable timely recommendations.

